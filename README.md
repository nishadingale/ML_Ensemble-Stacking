# ML_Ensemble-Stacking

##### In this project, which was part of a guided proect at coursera(Link Below), following tasks were completed.
https://coursera.org/share/fb464107b116c45802270994a42e6f89

* ##### Used advanced techniques for classification model optimization.
* ##### Worked with Wine dataset from the Scikit learn dataset library.
* ##### Building,fitting and visualizing models with Bagging and Stacking techniques.
* ##### Used RandomForest & DecisionTree classifiers from the Bagging techniques toolkit.
* ##### Used AdaBoost on Decision tree classifier to improve accuracy of the model.
* ##### Used XGBoost and GradientBoost Classifiers from Boosting techniques toolkit.
* ##### Used Heterogenous Ensemble learning with K-MeansNeighbor Classifier,Gaussian Naive-Bayes and RandomForest
* #####  Classifier as base models and LogisticRegression to determine the average outputs of all the above models.
* ##### Finally compared the performance of individual models with Stacking Ensemble learning. 

