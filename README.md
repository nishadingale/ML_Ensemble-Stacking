# ML_Ensemble-Stacking

##### In this project, which was part of a guided proect at coursera(Link Below), following tasks were completed.
https://coursera.org/share/fb464107b116c45802270994a42e6f89

##### Used advanced techniques for classification model optimization.
##### Worked with Wine dataset from the Scikit learn dataset library.
##### Building,fitting and visualizing models with Bagging and Stacking techniques.
##### Used RandomForest & DecisionTree classifiers from the Bagging techniques toolkit.
##### Used AdaBoost on Decision tree classifier to improve accuracy of the model.
##### Used XGBoost and GradientBoost Classifiers from Boosting techniques toolkit.
##### Used Heterogenous Ensemble learning with K-MeansNeighbor Classifier,Gaussian Naive-Bayes and RandomForest
#####  Classifier as base models and LogisticRegression to determine the average outputs of all the above models.
##### Finally compared the performance of individual models with Stacking Ensemble learning. 

